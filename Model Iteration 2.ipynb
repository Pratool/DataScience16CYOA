{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Iteration 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negations have come up time and time again to be a factor that causes phrases to be mis-categorized. In order to handle these cases, I will prepend a \"NOT\\_\" to the beginning of all the words that come after a negation phrase (these include \"not\", \"but\", \"didn't\" among others)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "df = pandas.DataFrame.from_csv('train.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SentenceId                                             Phrase  \\\n",
       "PhraseId                                                                  \n",
       "1                  1  A series of escapades demonstrating the adage ...   \n",
       "2                  1  A series of escapades demonstrating the adage ...   \n",
       "3                  1                                           A series   \n",
       "4                  1                                                  A   \n",
       "5                  1                                             series   \n",
       "\n",
       "          Sentiment  \n",
       "PhraseId             \n",
       "1                 1  \n",
       "2                 2  \n",
       "3                 2  \n",
       "4                 2  \n",
       "5                 2  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def prepend_NOT(match):\n",
    "    \"\"\"\n",
    "    A function that feeds into a regular expression substitution function\n",
    "    that prepends all words after a negation word (i.e. \"didn't\" and\n",
    "    \"not\") with \"NOT_\".\n",
    "    \"\"\"\n",
    "    match = match.group()\n",
    "    words = match.split(\" \")\n",
    "    negation = words[0]\n",
    "    del words[0]\n",
    "    new_words = [\"NOT_\" + word for word in words]\n",
    "    return negation + \" \" + \" \".join(new_words)\n",
    "\n",
    "\n",
    "def substitute_negations(phrase):\n",
    "    \"\"\"\n",
    "    Replaces input phrase with the same phrase, except prepending a \"NOT_\"\n",
    "    for every word after a negation word (i.e. \"didn't\" and \"not\"). This\n",
    "    can only occur in phrases with more than one word.\n",
    "    \"\"\"\n",
    "    # negation_words is a list of regular expressions\n",
    "    negation_words = [r\"not\", r\"n't\"]\n",
    "    \n",
    "    # negation_words then gets turned into a regular expression string\n",
    "    negation_words = [r\"(\" + word + r\")\" for word in negation_words]\n",
    "    negation_words = (r\"|\").join(negation_words)\n",
    "    \n",
    "    negations_re = re.compile(r\"(\" + negation_words + r\")[A-z ']*\")\n",
    "    substitution = negations_re.sub(prepend_NOT, phrase)\n",
    "    \n",
    "    if substitution == \"\":\n",
    "        return phrase\n",
    "    return substitution\n",
    "\n",
    "\n",
    "def add_NOT_to_negations(df):\n",
    "    \"\"\"\n",
    "    Replaces each phrase in the dataframe with the same phrase, but\n",
    "    replacing every word after a negation word (i.e. \"didn't\" and \"not\")\n",
    "    with \"NOT_\" prepended to the word. This can only occur in phrases\n",
    "    with more than one word.\n",
    "    \"\"\"\n",
    "    data = df\n",
    "    data[\"Negations\"] = data[\"Phrase\"].apply(lambda x: substitute_negations(x))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df01 = add_NOT_to_negations(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Negations</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2</td>\n",
       "      <td>This quiet , introspective and entertaining in...</td>\n",
       "      <td>4</td>\n",
       "      <td>This quiet , introspective and entertaining in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>3</td>\n",
       "      <td>Even fans of Ismail Merchant 's work , I suspe...</td>\n",
       "      <td>1</td>\n",
       "      <td>Even fans of Ismail Merchant 's work , I suspe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>4</td>\n",
       "      <td>A positively thrilling combination of ethnogra...</td>\n",
       "      <td>3</td>\n",
       "      <td>A positively thrilling combination of ethnogra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>5</td>\n",
       "      <td>Aggressive self-glorification and a manipulati...</td>\n",
       "      <td>1</td>\n",
       "      <td>Aggressive self-glorification and a manipulati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>6</td>\n",
       "      <td>A comedy-drama of nearly epic proportions root...</td>\n",
       "      <td>4</td>\n",
       "      <td>A comedy-drama of nearly epic proportions root...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>7</td>\n",
       "      <td>Narratively , Trouble Every Day is a plodding ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Narratively , Trouble Every Day is a plodding ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>8</td>\n",
       "      <td>The Importance of Being Earnest , so thick wit...</td>\n",
       "      <td>3</td>\n",
       "      <td>The Importance of Being Earnest , so thick wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>9</td>\n",
       "      <td>But it does n't leave you with much .</td>\n",
       "      <td>1</td>\n",
       "      <td>But it does n't NOT_leave NOT_you NOT_with NOT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>10</td>\n",
       "      <td>You could hate it for the same reason .</td>\n",
       "      <td>1</td>\n",
       "      <td>You could hate it for the same reason .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SentenceId                                             Phrase  \\\n",
       "PhraseId                                                                  \n",
       "1                  1  A series of escapades demonstrating the adage ...   \n",
       "64                 2  This quiet , introspective and entertaining in...   \n",
       "82                 3  Even fans of Ismail Merchant 's work , I suspe...   \n",
       "117                4  A positively thrilling combination of ethnogra...   \n",
       "157                5  Aggressive self-glorification and a manipulati...   \n",
       "167                6  A comedy-drama of nearly epic proportions root...   \n",
       "199                7  Narratively , Trouble Every Day is a plodding ...   \n",
       "214                8  The Importance of Being Earnest , so thick wit...   \n",
       "248                9              But it does n't leave you with much .   \n",
       "260               10            You could hate it for the same reason .   \n",
       "\n",
       "          Sentiment                                          Negations  \n",
       "PhraseId                                                                \n",
       "1                 1  A series of escapades demonstrating the adage ...  \n",
       "64                4  This quiet , introspective and entertaining in...  \n",
       "82                1  Even fans of Ismail Merchant 's work , I suspe...  \n",
       "117               3  A positively thrilling combination of ethnogra...  \n",
       "157               1  Aggressive self-glorification and a manipulati...  \n",
       "167               4  A comedy-drama of nearly epic proportions root...  \n",
       "199               1  Narratively , Trouble Every Day is a plodding ...  \n",
       "214               3  The Importance of Being Earnest , so thick wit...  \n",
       "248               1  But it does n't NOT_leave NOT_you NOT_with NOT...  \n",
       "260               1            You could hate it for the same reason .  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df01.drop_duplicates(['SentenceId']).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I would like to see if I can improve sentiment analysis by extracting what part of speech each word is. Part of speech (POS) tagging is an extensively studied NLP topic, however, each sentence is only tagged correctly probably just over 50% of the time (according to <a href=\"http://nlp.stanford.edu/pubs/CICLing2011-manning-tagging.pdf\">this paper</a>. I will use the well-rounded Perceptron Tagger implemented in the NLTK library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tag.perceptron import PerceptronTagger\n",
    "\n",
    "# Load the tagger for faster tagging\n",
    "tagger = PerceptronTagger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "def tag_all_phrases(df):\n",
    "    data = df\n",
    "    data[\"POS\"] = data[\"Phrase\"].apply(\n",
    "        lambda x: [tag[1] for tag in \\\n",
    "                   nltk.tag._pos_tag(nltk.word_tokenize(x), None, tagger)] )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df02 = tag_all_phrases(df01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Negations</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>[DT, NN, IN, NNS, VBG, DT, NN, IN, WP, VBZ, JJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2</td>\n",
       "      <td>This quiet , introspective and entertaining in...</td>\n",
       "      <td>4</td>\n",
       "      <td>This quiet , introspective and entertaining in...</td>\n",
       "      <td>[DT, JJ, ,, JJ, CC, JJ, JJ, VBZ, JJ, VBG, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>3</td>\n",
       "      <td>Even fans of Ismail Merchant 's work , I suspe...</td>\n",
       "      <td>1</td>\n",
       "      <td>Even fans of Ismail Merchant 's work , I suspe...</td>\n",
       "      <td>[RB, NNS, IN, NNP, NNP, POS, NN, ,, PRP, VBP, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>4</td>\n",
       "      <td>A positively thrilling combination of ethnogra...</td>\n",
       "      <td>3</td>\n",
       "      <td>A positively thrilling combination of ethnogra...</td>\n",
       "      <td>[DT, RB, VBG, NN, IN, NN, CC, PDT, DT, NN, ,, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>5</td>\n",
       "      <td>Aggressive self-glorification and a manipulati...</td>\n",
       "      <td>1</td>\n",
       "      <td>Aggressive self-glorification and a manipulati...</td>\n",
       "      <td>[JJ, NN, CC, DT, JJ, NN, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>6</td>\n",
       "      <td>A comedy-drama of nearly epic proportions root...</td>\n",
       "      <td>4</td>\n",
       "      <td>A comedy-drama of nearly epic proportions root...</td>\n",
       "      <td>[DT, NN, IN, RB, JJ, NNS, VBN, IN, DT, JJ, NN,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>7</td>\n",
       "      <td>Narratively , Trouble Every Day is a plodding ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Narratively , Trouble Every Day is a plodding ...</td>\n",
       "      <td>[RB, ,, JJ, DT, NNP, VBZ, DT, VBG, NN, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>8</td>\n",
       "      <td>The Importance of Being Earnest , so thick wit...</td>\n",
       "      <td>3</td>\n",
       "      <td>The Importance of Being Earnest , so thick wit...</td>\n",
       "      <td>[DT, NN, IN, NNP, NNP, ,, RB, JJ, IN, NN, PRP,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>9</td>\n",
       "      <td>But it does n't leave you with much .</td>\n",
       "      <td>1</td>\n",
       "      <td>But it does n't NOT_leave NOT_you NOT_with NOT...</td>\n",
       "      <td>[CC, PRP, VBZ, RB, VB, PRP, IN, JJ, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>10</td>\n",
       "      <td>You could hate it for the same reason .</td>\n",
       "      <td>1</td>\n",
       "      <td>You could hate it for the same reason .</td>\n",
       "      <td>[PRP, MD, VB, PRP, IN, DT, JJ, NN, .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SentenceId                                             Phrase  \\\n",
       "PhraseId                                                                  \n",
       "1                  1  A series of escapades demonstrating the adage ...   \n",
       "64                 2  This quiet , introspective and entertaining in...   \n",
       "82                 3  Even fans of Ismail Merchant 's work , I suspe...   \n",
       "117                4  A positively thrilling combination of ethnogra...   \n",
       "157                5  Aggressive self-glorification and a manipulati...   \n",
       "167                6  A comedy-drama of nearly epic proportions root...   \n",
       "199                7  Narratively , Trouble Every Day is a plodding ...   \n",
       "214                8  The Importance of Being Earnest , so thick wit...   \n",
       "248                9              But it does n't leave you with much .   \n",
       "260               10            You could hate it for the same reason .   \n",
       "\n",
       "          Sentiment                                          Negations  \\\n",
       "PhraseId                                                                 \n",
       "1                 1  A series of escapades demonstrating the adage ...   \n",
       "64                4  This quiet , introspective and entertaining in...   \n",
       "82                1  Even fans of Ismail Merchant 's work , I suspe...   \n",
       "117               3  A positively thrilling combination of ethnogra...   \n",
       "157               1  Aggressive self-glorification and a manipulati...   \n",
       "167               4  A comedy-drama of nearly epic proportions root...   \n",
       "199               1  Narratively , Trouble Every Day is a plodding ...   \n",
       "214               3  The Importance of Being Earnest , so thick wit...   \n",
       "248               1  But it does n't NOT_leave NOT_you NOT_with NOT...   \n",
       "260               1            You could hate it for the same reason .   \n",
       "\n",
       "                                                        POS  \n",
       "PhraseId                                                     \n",
       "1         [DT, NN, IN, NNS, VBG, DT, NN, IN, WP, VBZ, JJ...  \n",
       "64             [DT, JJ, ,, JJ, CC, JJ, JJ, VBZ, JJ, VBG, .]  \n",
       "82        [RB, NNS, IN, NNP, NNP, POS, NN, ,, PRP, VBP, ...  \n",
       "117       [DT, RB, VBG, NN, IN, NN, CC, PDT, DT, NN, ,, ...  \n",
       "157                             [JJ, NN, CC, DT, JJ, NN, .]  \n",
       "167       [DT, NN, IN, RB, JJ, NNS, VBN, IN, DT, JJ, NN,...  \n",
       "199               [RB, ,, JJ, DT, NNP, VBZ, DT, VBG, NN, .]  \n",
       "214       [DT, NN, IN, NNP, NNP, ,, RB, JJ, IN, NN, PRP,...  \n",
       "248                  [CC, PRP, VBZ, RB, VB, PRP, IN, JJ, .]  \n",
       "260                   [PRP, MD, VB, PRP, IN, DT, JJ, NN, .]  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df02.drop_duplicates([\"SentenceId\"]).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would be much easier to analyze if I could get the tags of the individual words. So I will, for human analysis sake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_words(df):\n",
    "    data = df[~(df['Phrase'].str.contains(' '))]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df02_words = get_words(df02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Negations</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>[DT]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>series</td>\n",
       "      <td>[NN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>2</td>\n",
       "      <td>of</td>\n",
       "      <td>[IN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>escapades</td>\n",
       "      <td>2</td>\n",
       "      <td>escapades</td>\n",
       "      <td>[NNS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>demonstrating</td>\n",
       "      <td>2</td>\n",
       "      <td>demonstrating</td>\n",
       "      <td>[VBG]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "      <td>2</td>\n",
       "      <td>the</td>\n",
       "      <td>[DT]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>adage</td>\n",
       "      <td>2</td>\n",
       "      <td>adage</td>\n",
       "      <td>[NN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>that</td>\n",
       "      <td>2</td>\n",
       "      <td>that</td>\n",
       "      <td>[IN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>what</td>\n",
       "      <td>2</td>\n",
       "      <td>what</td>\n",
       "      <td>[WP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>is</td>\n",
       "      <td>2</td>\n",
       "      <td>is</td>\n",
       "      <td>[VBZ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SentenceId         Phrase  Sentiment      Negations    POS\n",
       "PhraseId                                                            \n",
       "4                  1              A          2              A   [DT]\n",
       "5                  1         series          2         series   [NN]\n",
       "7                  1             of          2             of   [IN]\n",
       "9                  1      escapades          2      escapades  [NNS]\n",
       "12                 1  demonstrating          2  demonstrating  [VBG]\n",
       "14                 1            the          2            the   [DT]\n",
       "15                 1          adage          2          adage   [NN]\n",
       "17                 1           that          2           that   [IN]\n",
       "19                 1           what          2           what   [WP]\n",
       "21                 1             is          2             is  [VBZ]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df02_words.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I want to know all of the unique parts of speech in the words of this corpus. Unfortunately, the POS column is a list, which is not hashable, preventing me from using built-in pandas library functions. So I extract each POS and make a new column called POS2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_single_POS_from_words(df):\n",
    "    data = df\n",
    "    data[\"POS2\"] = data[\"POS\"].apply(lambda x: x[0])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-c:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df02_words01 = extract_single_POS_from_words(df02_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Negations</th>\n",
       "      <th>POS</th>\n",
       "      <th>POS2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>[DT]</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>series</td>\n",
       "      <td>[NN]</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>2</td>\n",
       "      <td>of</td>\n",
       "      <td>[IN]</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>escapades</td>\n",
       "      <td>2</td>\n",
       "      <td>escapades</td>\n",
       "      <td>[NNS]</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>demonstrating</td>\n",
       "      <td>2</td>\n",
       "      <td>demonstrating</td>\n",
       "      <td>[VBG]</td>\n",
       "      <td>VBG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "      <td>2</td>\n",
       "      <td>the</td>\n",
       "      <td>[DT]</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>adage</td>\n",
       "      <td>2</td>\n",
       "      <td>adage</td>\n",
       "      <td>[NN]</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>that</td>\n",
       "      <td>2</td>\n",
       "      <td>that</td>\n",
       "      <td>[IN]</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>what</td>\n",
       "      <td>2</td>\n",
       "      <td>what</td>\n",
       "      <td>[WP]</td>\n",
       "      <td>WP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>is</td>\n",
       "      <td>2</td>\n",
       "      <td>is</td>\n",
       "      <td>[VBZ]</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SentenceId         Phrase  Sentiment      Negations    POS POS2\n",
       "PhraseId                                                                 \n",
       "4                  1              A          2              A   [DT]   DT\n",
       "5                  1         series          2         series   [NN]   NN\n",
       "7                  1             of          2             of   [IN]   IN\n",
       "9                  1      escapades          2      escapades  [NNS]  NNS\n",
       "12                 1  demonstrating          2  demonstrating  [VBG]  VBG\n",
       "14                 1            the          2            the   [DT]   DT\n",
       "15                 1          adage          2          adage   [NN]   NN\n",
       "17                 1           that          2           that   [IN]   IN\n",
       "19                 1           what          2           what   [WP]   WP\n",
       "21                 1             is          2             is  [VBZ]  VBZ"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df02_words01.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT\n",
      "NN\n",
      "IN\n",
      "NNS\n",
      "VBG\n",
      "WP\n",
      "VBZ\n",
      "JJ\n",
      "RB\n",
      ",\n",
      "WDT\n",
      "CC\n",
      "TO\n",
      ".\n",
      "POS\n",
      "PRP\n",
      "MD\n",
      "VB\n",
      "CD\n",
      "VBN\n",
      "NNP\n",
      "EX\n",
      "PRP$\n",
      "VBP\n",
      "RBR\n",
      ":\n",
      "JJS\n",
      "``\n",
      "''\n",
      "WRB\n",
      "VBD\n",
      "JJR\n",
      "WP$\n",
      "$\n",
      "UH\n",
      "SYM\n",
      "LS\n",
      "#\n",
      "FW\n"
     ]
    }
   ],
   "source": [
    "for pos in df02_words01['POS2'].unique():\n",
    "    print pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll use the <a href=\"https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\">part of speech tags used by the Penn Treebank</a> as a reference for what the tags mean. Now I'll make a column for each of these unique parts of speech which represents whether or not that word is using this part of speech. It will be sparse for the most part (there will be many zeros)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def make_POS_columns(df):\n",
    "    data = df\n",
    "    for pos in df['POS2'].unique():\n",
    "        data[pos] = np.asarray((df['POS2'] == pos), dtype=int)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-c:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df02_words02 = make_POS_columns(df02_words01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Negations</th>\n",
       "      <th>POS</th>\n",
       "      <th>POS2</th>\n",
       "      <th>DT</th>\n",
       "      <th>NN</th>\n",
       "      <th>IN</th>\n",
       "      <th>NNS</th>\n",
       "      <th>...</th>\n",
       "      <th>WRB</th>\n",
       "      <th>VBD</th>\n",
       "      <th>JJR</th>\n",
       "      <th>WP$</th>\n",
       "      <th>$</th>\n",
       "      <th>UH</th>\n",
       "      <th>SYM</th>\n",
       "      <th>LS</th>\n",
       "      <th>#</th>\n",
       "      <th>FW</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>DT</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>series</td>\n",
       "      <td>0</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>2</td>\n",
       "      <td>of</td>\n",
       "      <td>0</td>\n",
       "      <td>IN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>escapades</td>\n",
       "      <td>2</td>\n",
       "      <td>escapades</td>\n",
       "      <td>0</td>\n",
       "      <td>NNS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>demonstrating</td>\n",
       "      <td>2</td>\n",
       "      <td>demonstrating</td>\n",
       "      <td>0</td>\n",
       "      <td>VBG</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "      <td>2</td>\n",
       "      <td>the</td>\n",
       "      <td>0</td>\n",
       "      <td>DT</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>adage</td>\n",
       "      <td>2</td>\n",
       "      <td>adage</td>\n",
       "      <td>0</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>that</td>\n",
       "      <td>2</td>\n",
       "      <td>that</td>\n",
       "      <td>0</td>\n",
       "      <td>IN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>what</td>\n",
       "      <td>2</td>\n",
       "      <td>what</td>\n",
       "      <td>0</td>\n",
       "      <td>WP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>is</td>\n",
       "      <td>2</td>\n",
       "      <td>is</td>\n",
       "      <td>0</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SentenceId         Phrase  Sentiment      Negations  POS POS2  DT  \\\n",
       "PhraseId                                                                      \n",
       "4                  1              A          2              A    0   DT   1   \n",
       "5                  1         series          2         series    0   NN   0   \n",
       "7                  1             of          2             of    0   IN   0   \n",
       "9                  1      escapades          2      escapades    0  NNS   0   \n",
       "12                 1  demonstrating          2  demonstrating    0  VBG   0   \n",
       "14                 1            the          2            the    0   DT   1   \n",
       "15                 1          adage          2          adage    0   NN   0   \n",
       "17                 1           that          2           that    0   IN   0   \n",
       "19                 1           what          2           what    0   WP   0   \n",
       "21                 1             is          2             is    0  VBZ   0   \n",
       "\n",
       "          NN  IN  NNS ...  WRB  VBD  JJR  WP$  $  UH  SYM  LS  #  FW  \n",
       "PhraseId              ...                                             \n",
       "4          0   0    0 ...    0    0    0    0  0   0    0   0  0   0  \n",
       "5          1   0    0 ...    0    0    0    0  0   0    0   0  0   0  \n",
       "7          0   1    0 ...    0    0    0    0  0   0    0   0  0   0  \n",
       "9          0   0    1 ...    0    0    0    0  0   0    0   0  0   0  \n",
       "12         0   0    0 ...    0    0    0    0  0   0    0   0  0   0  \n",
       "14         0   0    0 ...    0    0    0    0  0   0    0   0  0   0  \n",
       "15         1   0    0 ...    0    0    0    0  0   0    0   0  0   0  \n",
       "17         0   1    0 ...    0    0    0    0  0   0    0   0  0   0  \n",
       "19         0   0    0 ...    0    0    0    0  0   0    0   0  0   0  \n",
       "21         0   0    0 ...    0    0    0    0  0   0    0   0  0   0  \n",
       "\n",
       "[10 rows x 44 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df02_words02.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
