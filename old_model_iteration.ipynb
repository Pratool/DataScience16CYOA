{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import re\n",
    "\n",
    "def stem_phrases(data):\n",
    "    df = data\n",
    "    \n",
    "    # looks for any commas, periods, and apostrophes with any leading or following spaces\n",
    "    remove_punct = r'(( )*((\\.)|(\\'s*)|(,))( )*)'\n",
    "\n",
    "    # remove leading and trailing spaces\n",
    "    remove_spaces = r'(^( )*)|(( )*$)'\n",
    "\n",
    "    # replaces the pattern mentioned above with a single space\n",
    "    df['Phrase'] = df['Phrase'].str.replace(remove_punct, ' ')\n",
    "    df = df[df['Phrase'] != ' ']\n",
    "    #print df[df.loc(df['Phrase'] != ' ')]\n",
    "    #df = df.loc(df['Phrase'] != ' ')\n",
    "    df['Phrase'] = df['Phrase'].str.replace(remove_spaces, '')\n",
    "\n",
    "    # Removes empty string phrases from the list\n",
    "    B = []\n",
    "    before = \"\"\n",
    "    for r in df['Phrase']:\n",
    "        if r != before:\n",
    "            B.append(True)\n",
    "            before = r\n",
    "        else:\n",
    "            B.append(False)\n",
    "    df = df[B]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pandas.DataFrame.from_csv('train.tsv', sep='\\t')\n",
    "#stemmed = stem_phrases(df)\n",
    "#stemmed.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_words(df):\n",
    "    data = df[~(df['Phrase'].str.contains(' '))]\n",
    "    return data\n",
    "\n",
    "def get_sentences(df):\n",
    "    sentences = df.drop_duplicates(['SentenceId'])\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>escapades</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>demonstrating</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>adage</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>that</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>what</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>is</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>good</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>for</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>also</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>gander</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>,</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>some</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>which</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>occasionally</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>amuses</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "      <td>but</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1</td>\n",
       "      <td>amounts</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1</td>\n",
       "      <td>to</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1</td>\n",
       "      <td>much</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1</td>\n",
       "      <td>story</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2</td>\n",
       "      <td>This</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2</td>\n",
       "      <td>quiet</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2</td>\n",
       "      <td>introspective</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2</td>\n",
       "      <td>and</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2</td>\n",
       "      <td>entertaining</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2</td>\n",
       "      <td>independent</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2</td>\n",
       "      <td>worth</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2</td>\n",
       "      <td>seeking</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>3</td>\n",
       "      <td>Even</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>3</td>\n",
       "      <td>fans</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>3</td>\n",
       "      <td>Ismail</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>3</td>\n",
       "      <td>Merchant</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>3</td>\n",
       "      <td>'s</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>3</td>\n",
       "      <td>work</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>3</td>\n",
       "      <td>I</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>3</td>\n",
       "      <td>suspect</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>3</td>\n",
       "      <td>would</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>3</td>\n",
       "      <td>have</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SentenceId         Phrase  Sentiment\n",
       "PhraseId                                      \n",
       "4                  1              A          2\n",
       "5                  1         series          2\n",
       "7                  1             of          2\n",
       "9                  1      escapades          2\n",
       "12                 1  demonstrating          2\n",
       "14                 1            the          2\n",
       "15                 1          adage          2\n",
       "17                 1           that          2\n",
       "19                 1           what          2\n",
       "21                 1             is          2\n",
       "23                 1           good          3\n",
       "25                 1            for          2\n",
       "27                 1          goose          2\n",
       "31                 1           also          2\n",
       "37                 1         gander          2\n",
       "38                 1              ,          2\n",
       "41                 1           some          2\n",
       "43                 1          which          2\n",
       "45                 1   occasionally          2\n",
       "47                 1         amuses          3\n",
       "49                 1            but          2\n",
       "51                 1           none          2\n",
       "55                 1        amounts          2\n",
       "57                 1             to          2\n",
       "59                 1           much          2\n",
       "62                 1          story          2\n",
       "63                 1              .          2\n",
       "66                 2           This          2\n",
       "69                 2          quiet          2\n",
       "73                 2  introspective          2\n",
       "74                 2            and          2\n",
       "75                 2   entertaining          4\n",
       "76                 2    independent          2\n",
       "80                 2          worth          2\n",
       "81                 2        seeking          2\n",
       "85                 3           Even          2\n",
       "86                 3           fans          3\n",
       "90                 3         Ismail          2\n",
       "92                 3       Merchant          2\n",
       "93                 3             's          2\n",
       "94                 3           work          2\n",
       "99                 3              I          2\n",
       "100                3        suspect          2\n",
       "103                3          would          2\n",
       "105                3           have          2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = get_words(df)\n",
    "words.head(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tag.perceptron import PerceptronTagger\n",
    "\n",
    "# Load the tagger for faster tagging\n",
    "tagger = PerceptronTagger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tag_sentences(df):\n",
    "    data = df\n",
    "    data[\"POS\"] = data[\"Phrase\"].apply(lambda x: nltk.tag._pos_tag(nltk.word_tokenize(x), None, tagger))\n",
    "    return data\n",
    "\n",
    "# I wasn't able to put the tags on each word after tagging each sentence\n",
    "# This is due to the stemming done earlier\n",
    "def tag_words(words, sentences):\n",
    "    possible_tags = ['CC', 'CD', 'DT', 'EX',\n",
    "                     'FW', 'IN', 'JJ', 'JJR',\n",
    "                     'JJS', 'LS', 'MD', 'NN',\n",
    "                     'NNP', 'NNPS', 'NNS', 'PDT',\n",
    "                     'POS', 'PRP', 'PRP$', 'RB',\n",
    "                     'RBR', 'RBS', 'RP', 'SYM',\n",
    "                     'TO', 'UH', 'VB', 'VBD',\n",
    "                     'VBG', 'VBN', 'VBP', 'VBZ',\n",
    "                     'WDT', 'WDT', 'WP', 'WP$',\n",
    "                     'WRB']\n",
    "    data = []\n",
    "    words_with_pos = words\n",
    "    j = 0\n",
    "    for sentence_id, sentence_pos in zip(sentences[\"SentenceId\"], sentences[\"POS\"]):\n",
    "        sentence_words = words[words[\"SentenceId\"] == sentence_id]\n",
    "        #data.append(sentence_pos)\n",
    "        for sentence_word_pos in sentence_pos:\n",
    "            if j == 0:\n",
    "                print sentence_word_pos\n",
    "                j += 1\n",
    "            data.append(sentence_word_pos[1])\n",
    "    for m,n in zip(words_with_pos.Phrase, data):\n",
    "        if j < 45:\n",
    "            print m, n\n",
    "            j += 1\n",
    "    print len(words_with_pos), len(data)\n",
    "    words_with_pos[\"POS\"] = data\n",
    "    return words_with_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tag_words2(words):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          SentenceId                                             Phrase  \\\n",
      "PhraseId                                                                  \n",
      "1                  1  A series of escapades demonstrating the adage ...   \n",
      "64                 2  This quiet , introspective and entertaining in...   \n",
      "82                 3  Even fans of Ismail Merchant 's work , I suspe...   \n",
      "\n",
      "          Sentiment  \n",
      "PhraseId             \n",
      "1                 1  \n",
      "64                4  \n",
      "82                1  \n"
     ]
    }
   ],
   "source": [
    "sentences = get_sentences(df)\n",
    "print sentences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-c:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "tagged_sentences = tag_sentences(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[(A, DT), (series, NN), (of, IN), (escapades, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2</td>\n",
       "      <td>This quiet , introspective and entertaining in...</td>\n",
       "      <td>4</td>\n",
       "      <td>[(This, DT), (quiet, JJ), (,, ,), (introspecti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>3</td>\n",
       "      <td>Even fans of Ismail Merchant 's work , I suspe...</td>\n",
       "      <td>1</td>\n",
       "      <td>[(Even, RB), (fans, NNS), (of, IN), (Ismail, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>4</td>\n",
       "      <td>A positively thrilling combination of ethnogra...</td>\n",
       "      <td>3</td>\n",
       "      <td>[(A, DT), (positively, RB), (thrilling, VBG), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>5</td>\n",
       "      <td>Aggressive self-glorification and a manipulati...</td>\n",
       "      <td>1</td>\n",
       "      <td>[(Aggressive, JJ), (self-glorification, NN), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>6</td>\n",
       "      <td>A comedy-drama of nearly epic proportions root...</td>\n",
       "      <td>4</td>\n",
       "      <td>[(A, DT), (comedy-drama, NN), (of, IN), (nearl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>7</td>\n",
       "      <td>Narratively , Trouble Every Day is a plodding ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[(Narratively, RB), (,, ,), (Trouble, JJ), (Ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>8</td>\n",
       "      <td>The Importance of Being Earnest , so thick wit...</td>\n",
       "      <td>3</td>\n",
       "      <td>[(The, DT), (Importance, NN), (of, IN), (Being...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>9</td>\n",
       "      <td>But it does n't leave you with much .</td>\n",
       "      <td>1</td>\n",
       "      <td>[(But, CC), (it, PRP), (does, VBZ), (n't, RB),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>10</td>\n",
       "      <td>You could hate it for the same reason .</td>\n",
       "      <td>1</td>\n",
       "      <td>[(You, PRP), (could, MD), (hate, VB), (it, PRP...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SentenceId                                             Phrase  \\\n",
       "PhraseId                                                                  \n",
       "1                  1  A series of escapades demonstrating the adage ...   \n",
       "64                 2  This quiet , introspective and entertaining in...   \n",
       "82                 3  Even fans of Ismail Merchant 's work , I suspe...   \n",
       "117                4  A positively thrilling combination of ethnogra...   \n",
       "157                5  Aggressive self-glorification and a manipulati...   \n",
       "167                6  A comedy-drama of nearly epic proportions root...   \n",
       "199                7  Narratively , Trouble Every Day is a plodding ...   \n",
       "214                8  The Importance of Being Earnest , so thick wit...   \n",
       "248                9              But it does n't leave you with much .   \n",
       "260               10            You could hate it for the same reason .   \n",
       "\n",
       "          Sentiment                                                POS  \n",
       "PhraseId                                                                \n",
       "1                 1  [(A, DT), (series, NN), (of, IN), (escapades, ...  \n",
       "64                4  [(This, DT), (quiet, JJ), (,, ,), (introspecti...  \n",
       "82                1  [(Even, RB), (fans, NNS), (of, IN), (Ismail, N...  \n",
       "117               3  [(A, DT), (positively, RB), (thrilling, VBG), ...  \n",
       "157               1  [(Aggressive, JJ), (self-glorification, NN), (...  \n",
       "167               4  [(A, DT), (comedy-drama, NN), (of, IN), (nearl...  \n",
       "199               1  [(Narratively, RB), (,, ,), (Trouble, JJ), (Ev...  \n",
       "214               3  [(The, DT), (Importance, NN), (of, IN), (Being...  \n",
       "248               1  [(But, CC), (it, PRP), (does, VBZ), (n't, RB),...  \n",
       "260               1  [(You, PRP), (could, MD), (hate, VB), (it, PRP...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sentences.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('A', 'DT')\n",
      "A DT\n",
      "series NN\n",
      "of IN\n",
      "escapades NNS\n",
      "demonstrating VBG\n",
      "the DT\n",
      "adage NN\n",
      "that IN\n",
      "what WP\n",
      "is VBZ\n",
      "good JJ\n",
      "for IN\n",
      "goose DT\n",
      "also NN\n",
      "gander VBZ\n",
      ", RB\n",
      "some JJ\n",
      "which IN\n",
      "occasionally DT\n",
      "amuses NN\n",
      "but ,\n",
      "none DT\n",
      "amounts IN\n",
      "to WDT\n",
      "much RB\n",
      "story VBZ\n",
      ". CC\n",
      "This NN\n",
      "quiet IN\n",
      "introspective WDT\n",
      "and NNS\n",
      "entertaining TO\n",
      "independent JJ\n",
      "worth IN\n",
      "seeking DT\n",
      "Even NN\n",
      "fans .\n",
      "Ismail DT\n",
      "Merchant JJ\n",
      "'s ,\n",
      "work JJ\n",
      "I CC\n",
      "suspect JJ\n",
      "would JJ\n",
      "16531 162121\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-98710a018908>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtagged_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtag_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagged_sentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#for i in range(len(tagged_words[0])+1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#    print tagged_words[i]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtagged_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-f0fa0adca62c>\u001b[0m in \u001b[0;36mtag_words\u001b[1;34m(words, sentences)\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0mj\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords_with_pos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mwords_with_pos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"POS\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwords_with_pos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2297\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2298\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2299\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2301\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2366\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2367\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2523\u001b[0m             \u001b[1;31m# turn me into an ndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2524\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_sanitize_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2525\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2526\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m_sanitize_index\u001b[1;34m(data, index, copy)\u001b[0m\n\u001b[0;32m   2739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2740\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2741\u001b[1;33m         raise ValueError('Length of values does not match length of '\n\u001b[0m\u001b[0;32m   2742\u001b[0m                          'index')\n\u001b[0;32m   2743\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "tagged_words = tag_words(words, tagged_sentences)\n",
    "#for i in range(len(tagged_words[0])+1):\n",
    "#    print tagged_words[i]\n",
    "tagged_words.head(5)\n",
    "\n",
    "#Why are the lengths off by so much?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tag_sentences(df):\n",
    "    data = df\n",
    "    data[\"POS\"] = data[\"Phrase\"].apply(lambda x: nltk.pos_tag(nltk.word_tokenize(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to handle negations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_negative(df):\n",
    "    for phr in df:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
